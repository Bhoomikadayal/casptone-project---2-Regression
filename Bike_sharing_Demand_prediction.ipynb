{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhoomikadayal/casptone-project---2-Regression/blob/main/Bike_sharing_Demand_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - Bike Sharing Demand Prediction \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - TEAM \n",
        "##### **Team Name** - TEAM DENVER\n",
        "##### **Team Member 1 -**  Sumit Ghanghas   \n",
        "##### **Team Member 2 -**  Bhoomika Dhayal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "##### **Team Member 1 -**  Sumit Ghanghas \n",
        "https://github.com/ghanghas291/casptone-project-ML\n",
        "##### **Team Member 2 -**  Bhoomika Dhayal\n",
        "https://github.com/Bhoomikadayal/casptone-project---2-Regression.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "According to recent studies, it is expected that more than 60% of the population in the world tends to goes toward cities. \n",
        "\n",
        "Bike-sharing MOD systems are already firmly holding the effective part in short commuting for short trips in several cities. There are certain issues in the maintenance, design, and management of bike-sharing systems (ex :- layout of the station design; fleet size and capacity of the station; detecting broken, lost, or theft bikes; pricing; monitoring of traffic and customer activities to promote behaviour virtuously; and marketing using campaigns etc). \n",
        "\n",
        "System balancing is the hardest policies. \n",
        "Today, bike-sharing systems are blooming across more cities around the world. To complete a short trip renting a bike is a better way as compared to walking. It is eco-friendly and comfortable too compared to driving.\n",
        "\n",
        "Data which is collected from a rented bike provider company form Seoul to get analysed, involves usage details of customers from.  The data was taken from rented bike Provider Company. It has 8760 rows and 14 columns. Most columns related to hourly bike count for rent. Other column was indicative of weather condition affecting bike count per hour.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "### The main goal of the project is to: Finding factors and cause those influence shortage of bike and time delay of availing bike on rent. \n",
        "\n",
        "#### 1. To make  maximize the availability of bikes to the customer.\n",
        "#### 2. Minimize the time of waiting to get a bike on rent.\n",
        "#### 3. The final aim of this project is the prediction of bike count required at each hour for the stable supply of rental bikes.\n",
        "#### 4. Using the data provided, this paper aims to analyze the data to determine what variables are correlated with customer churn, if any. Hourly count of bike for rent will also be predicted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhDvGCAqmjP1"
      },
      "source": [
        "# **Business Understanding**\n",
        "\n",
        "#### 1. A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. \n",
        "#### 2. Rental Bike Sharing is the process by which bicycles are procured on several basis- hourly, weekly, membership-wise, etc.\n",
        "#### 3. Today, bike-sharing systems are blooming across more cities around the world. To complete a short trip renting a bike is a faster way when compared to walking\n",
        "#### 4. Mostly used by those people having no personal vehicle and avoid public transport and private cabs , so they prefer rental bikes\n",
        "#### 5. In our project, we chose to analyses a dataset pertaining to Rental Bike Demand from South Korean city of Seoul.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "  #### Date:   The date of the day, during 365 days from 01/12/2017 to 30/11/2018, formatting in DD/MM/YYYY, we need to convert into date-time format. \n",
        " #### Rented Bike Count:   Number of rented bikes per hour which our dependent variable and we need to predict that\n",
        " #### Hour:   The hour of the day, starting from 0-23 it's in a digital time format\n",
        " #### Temperature (°C):    Temperature of the weather in Celsius and it varies from -17°C to 39.4°C.\n",
        " #### Humidity (%):   Availability of Humidity in the air during the booking and ranges from 0 to 98%.\n",
        " #### Wind speed (m/s):   Speed of the wind while booking and ranges from 0 to 7.4m/s.\n",
        " #### Visibility (10m):  Visibility to the eyes during driving in “m” and ranges from 27m to 2000m.\n",
        " #### Dew point temperature (°C):   Temperature  At the beginning of the day and it ranges from -30.6°C to 27.2°C.\n",
        " #### Solar Radiation (MJ/m2):    Sun contribution or solar radiation during ride booking which varies from 0 to 3.5 MJ/m2.\n",
        " #### Rainfall (mm):   The amount of rainfall during bike booking which ranges from 0 to 35mm. \n",
        " #### Snowfall (cm):   Amount of snowing in cm during the booking in cm and ranges from 0 to 8.8 cm.\\\n",
        " #### Seasons:  Seasons of the year and total there are 4 distinct seasons I.e. summer, autumn, spring and winter.\n",
        " #### Holiday:   If the day is holiday period or not and there are 2 types of data that is holiday and no holiday \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # for "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# mount the dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCmkjMzChHk6"
      },
      "outputs": [],
      "source": [
        "# load the data set from drive\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/casptone project - 2 (Regression)/SeoulBikeData.csv\", encoding=\"latin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "P0iJBH69y6oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count\n",
        "it tells us that there is 8740 rows and 14 columns in that dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYCXwxTfhHlA"
      },
      "source": [
        "There is no values in that dataset. That is the best thing in that data it saves too much time in real time dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-RD77Z1hHlB"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "a = df.duplicated().sum()\n",
        "print(f\"the duplicates values in data is {a}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "We found that there is no duplicates values in that data set and no null values that makes easy for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe (Looking for the description of the dataset to get insights of the data)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "* ***This Dataset contains 8760 lines and 14 columns.*** \n",
        "***In a day we have 24 hours and we have 365 days a year .**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRp8QI2_hHlJ"
      },
      "outputs": [],
      "source": [
        "#Rename the complex columns name\n",
        "df=df.rename(columns={'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-XQn3HkhHlI"
      },
      "source": [
        "### As we know we had 8760 observations and 14 features. \n",
        "#### Categorical Features:  Seasons, Holiday and Functioning day.\n",
        "#### Numerical Columns: Date, Hour, Temperature, Humidity, Wind speed, Visibility, Dew point temperature, Solar radiation, Rainfall, Snowfall, Rented Bike count .\n",
        "Rename Columns: We renamed columns because they had units mentioned in brackets and was difficult to copy the feature name while working Change column name because ihas units with name "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5fB9-1ahHlJ"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMh93wQPhHlK"
      },
      "outputs": [],
      "source": [
        "# Changing the \"Date\" column into three \"year\",\"month\",\"day\" column\n",
        "df['Date'] = df['Date'].apply(lambda x: \n",
        "                                    dt.datetime.strptime(x,\"%d/%m/%Y\"))\n",
        "\n",
        "df['year'] = df['Date'].dt.year\n",
        "df['month'] = df['Date'].dt.month\n",
        "df['day'] = df['Date'].dt.day_name()\n",
        "#creating a new column of \"weekdays_weekend\" \n",
        "df['weekdays_weekend']=df['day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )\n",
        "# drop date column\n",
        "df=df.drop(columns=['Date','day','year'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "id": "rSNbZBNEyemA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDw9fPkUhHlK"
      },
      "source": [
        "### breaking date column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "We don't found any null values and no duplicates values  so it's clear that the data is neat and clean for visualizating and ready fot visualizating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code  \n",
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.barplot(data=df,x='Seasons',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Seasons ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "#### conclusion : Summer season had the highest Bike Rent Count. People are more likely to take rented bikes in summer. Bike rentals in winter is very less compared to other seasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.barplot(data=df,x='month',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Month ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wYz4tCohHlP"
      },
      "source": [
        "####  conclusion : From March Bike Rent Count started  increasing and it was highest in June."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.barplot(data=df,x='Holiday',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_2YnhAhHlP"
      },
      "source": [
        "#### conclusion: High number of bikes were rented on No Holidays. Which is almost 700 bikes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.barplot(data=df,x='Functioning_Day',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "#### conclusion : Zero Bikes were rented on no functioning day.More than 700 bikes rented on functioning day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.barplot(data=df,x='weekdays_weekend',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='1 for saturday/sunday   0 :- foother days ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9I_v2Q5hHlT"
      },
      "source": [
        "#### conclusion : More than 700 bikes were rented on weekdays. On weekend, almost 650 bikes were rented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented_Bike_Count',hue='Holiday',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEPzQJvAhHlX"
      },
      "source": [
        "#### There is sudden peak between 6/7AM to 10 AM. Office /College going time could be the reason for this sudden peak on NO Holiday. But on Holiday the case is different,very less bike rentals happened.\n",
        "\n",
        " #### Again there is peak between 4PM to 7 PM. may be its office leaving time for the above people.( NO Holiday).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented_Bike_Count',hue='Functioning_Day',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "#### conclusion : Here the trend for functioning day is same as of No holiday. Only the difference is on No functioning day there were zero bike rentals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "fig,ax=plt.subplots(figsize=(8,8))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented_Bike_Count',hue='Seasons',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to seasons ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75L4VOFRhHla"
      },
      "source": [
        "#### In summer season the use of rented bike is high and peak time is 7am-9am and 7pm-5pm\n",
        "#### In winter season the use of rented bike is very low because of snowfall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "fig,ax=plt.subplots(figsize=(6,6))\n",
        "sns.pointplot(data=df,x='Hour',y='Rented_Bike_Count',hue='weekdays_weekend',ax=ax)\n",
        "ax.set(title='1 for sunday/saturday   0 for other day ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBpY5ekJphqQ"
      },
      "source": [
        "#### we can say that in the weekdays which represent in blue line graph show that the demand of the bike higher because of the office Time are 7 am to 9 am and 5 pm to 7 pm\n",
        "\n",
        "#### The orange line graph represent the weekend days, and it show that the demand of rented bikes are very low trend from 0 to 11 and starting to increase from 11 till 17 and start to decrese after that till 23 ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b8GIP0DhHlb"
      },
      "source": [
        "#### **For categorical values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIkephHFhHlb"
      },
      "outputs": [],
      "source": [
        "#Change the int64 column into catagory column\n",
        "cols=['Hour','month','weekdays_weekend']\n",
        "for col in cols:\n",
        "  df[col]=df[col].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxNPSIeUhHlc"
      },
      "source": [
        "# **Check skewness and disrtibution of Numerical Variable**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jgcrj5UbhHlc"
      },
      "source": [
        "### Numerical variable :-\n",
        "#### Numerical data is a data type that contains numberical values, it is also called quantitative data, \n",
        "#### It has two types \n",
        "#### 1. Discrete \n",
        "#### 2. Conitnous "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL7GvrjIhHlc"
      },
      "source": [
        "#### Analyze  Numerical variables  using distplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQsp7Fr3hHld"
      },
      "outputs": [],
      "source": [
        "#assign the numerical coulmn to variavle\n",
        "num_columns=list(df.select_dtypes(['int64','float64']).columns)   # it contains those column which have datatype int and float into a list\n",
        "num_features=pd.Index(num_columns)    # it convert index to column   in panda dataframe because we need columns\n",
        "num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHFz3AFwhHle"
      },
      "outputs": [],
      "source": [
        "# it print all displots to check skewness and  the distribution of all numerical features\n",
        "for col in num_features:  # we make a function where all column are added\n",
        "  plt.figure(figsize=(4,3))\n",
        "  sns.distplot(x=df[col])\n",
        "  plt.xlabel(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJGW1KQehHle"
      },
      "source": [
        "* ***we see that people like to ride bikes when it is pretty hot around 25°C in average***\n",
        "* ***of \"Dew_point_temperature' is almost same as the 'temperature' there is some similarity present we can check it in our next step.***\n",
        "* ***we see that, the amount of rented bikes is huge, when there is solar radiation, the counter of rents is around 1000***\n",
        "* ***We see that, on the y-axis, the amount of rented bike is very low When we have more than 4 cm of snow, the bike rents is much lower***\n",
        "* ***We see that even if it rains a lot the demand of of rent bikes is not decreasing, here for example even if we have 20 mm of rain there is a big peak of rented bikes***\n",
        "* ***We can see from the above plot that the demand of rented bike is uniformly distribute despite of wind speed but when the speed of wind was 7 m/s then the demand of bike also increase that clearly means peoples love to ride bikes when its little windy.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47uepOQthHlf"
      },
      "source": [
        "### **Check Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o499A9aJhHlf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.subplot(3, 3, 1)\n",
        "_ = sns.histplot(x='Temperature', data=df)\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "_ = sns.histplot(x='Dew_point_temperature', data=df)\n",
        "\n",
        "plt.subplot(3, 3,3)\n",
        "_ = sns.histplot(x='Humidity', data=df)\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "_ = sns.histplot(x='Wind_speed', data=df)\n",
        "\n",
        "plt.subplot(3, 3,5)\n",
        "_ = sns.histplot(x='Solar_Radiation', data=df)\n",
        "\n",
        "plt.subplot(3, 3,6)\n",
        "_ = sns.histplot(x='Visibility', data=df)\n",
        "\n",
        "plt.subplot(3, 3,7)\n",
        "_ = sns.histplot(x='Rainfall', data=df)\n",
        "\n",
        "plt.subplot(3, 3,8)\n",
        "_ = sns.histplot(x='Snowfall', data=df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rofioT26hHlg"
      },
      "source": [
        "### **Check realtion using Regression plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MvHg10fhHlg"
      },
      "outputs": [],
      "source": [
        "#printing the regression plot for all the numerical features\n",
        "for col in num_features:     \n",
        "  fig,ax=plt.subplots(figsize=(4,4))\n",
        "  sns.regplot(x=df[col],y=df['Rented_Bike_Count'],scatter_kws={\"color\": 'orange'}, line_kws={\"color\": \"black\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cd0t4sohHlh"
      },
      "source": [
        "####  Regression plot of all numerical features having columns  'Temperature', 'Wind_speed','Visibility', 'Dew_point_temperature', 'Solar_Radiation' are positively relation rental_bike_count. Which means there are a direct relationship between the rented bike count and features when features increase demand for rent bike also increase. On the other Hand\n",
        "#### 'Rainfall','Snowfall','Humidity' these features are negatively related with rental_bike_count. Which means the rented bike count decreases when these features increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4oSIXw4hHlh"
      },
      "source": [
        "## **Checking Outlier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LGyhogDhHlh"
      },
      "outputs": [],
      "source": [
        "#Boxplot of Rented Bike Count to check outliers\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=df['Rented_Bike_Count'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yw7veSQhHlh"
      },
      "source": [
        "#### The above boxplot shows that we have detect outliers in Rented Bike Count column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V1KX72ihHli"
      },
      "source": [
        "## **Remove Outlier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvR6XCW4hHli"
      },
      "outputs": [],
      "source": [
        "#After applying sqrt on Rented Bike Count check wheater we still have outliers \n",
        "plt.figure(figsize=(5,3))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=np.sqrt(df['Rented_Bike_Count']))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00W--HHFhHli"
      },
      "source": [
        "#### After applying Square root to the Rented Bike Count column, we find that there is no outliers present."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFkkMReAhHlj"
      },
      "source": [
        "## **Check Corellation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JqJn1KrhHlj"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "## plot the Correlation matrix\n",
        "plt.figure(figsize=(15,6))\n",
        "correlation=df.corr()\n",
        "sns.heatmap((correlation), annot=True,cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "***We can observe on the heatmap that on the rental_bike_count line the most positively correlated variables to the rent are :***\n",
        "\n",
        "* the temperature\n",
        "* the dew point temperature\n",
        "* the solar radiation\n",
        "\n",
        "***And most negatively correlated variables are:***\n",
        "* Humidity\n",
        "* Rainfall\n",
        "* Snowfall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHCxr4hHhHln"
      },
      "source": [
        "# **Categorical Encoding / Create the dummy variables**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6wjK1_3hHln"
      },
      "source": [
        "#### This data has some categorical values. computer cannot understand categorical valuse so we convert into dummy variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxNUYsXlhHlo"
      },
      "outputs": [],
      "source": [
        "#Assign all catagoriacla features to a variable\n",
        "categorical_features=list(df.select_dtypes(['object','category']).columns)   # here we call all column having datatype object/cateogry\n",
        "categorical_features=pd.Index(categorical_features)   # here convert index into column\n",
        "categorical_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyJ3BdEhHlo"
      },
      "source": [
        "#### One hot coding in 0/1 foramt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-gmrqZehHlo"
      },
      "outputs": [],
      "source": [
        "#creat a copy\n",
        "df_copy = df\n",
        "\n",
        "def one_hot_encoding(data, column):\n",
        "    data = pd.concat([data, pd.get_dummies(data[column], prefix=column, drop_first=True)], axis=1)\n",
        "    data = data.drop([column], axis=1)\n",
        "    return data\n",
        "\n",
        "for col in categorical_features:\n",
        "    df_copy = one_hot_encoding(df_copy, col)   #  here we use one_hot_encoding function\n",
        "df_copy.head()     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcGeiVX5hHlo"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wygRK7chHlp"
      },
      "source": [
        "### **1. Train Test split for regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co-L3cdThHlp"
      },
      "source": [
        "Before, fitting any model there is a rule of thumb to split the dataset into a training and test set.is it means that 80 % goes fo training the model and some portion will be used to check that our model is performing on any unseen data. 20 % for  testing . In this step we will split our data into training and testing set using scikit learn library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xOFwTkOhHlp"
      },
      "outputs": [],
      "source": [
        "#Assign the value in X and Y\n",
        "X = df_copy.drop(columns=['Rented_Bike_Count'], axis=1)\n",
        "y = np.sqrt(df_copy['Rented_Bike_Count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcZBKBY9hHlp"
      },
      "outputs": [],
      "source": [
        "X.head()   # here we check that our data is split proper or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0em-I3gohHlp"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elTynOydhHlq"
      },
      "source": [
        "#### train and test data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z24SEt7LhHlq"
      },
      "outputs": [],
      "source": [
        "#Creat test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqo-9K6jhHlq"
      },
      "outputs": [],
      "source": [
        "df_copy.describe().columns   # here we check all column in traiinig data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPfIuq6ThHlq"
      },
      "source": [
        "### **Formula for Linear regrssion model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDY6EFiYhHlr"
      },
      "source": [
        "* MSE formula = (1/n) * Σ(actual – forecast)2\n",
        "Where:\n",
        "\n",
        "*   n = number of items,\n",
        "* Σ = summation notation,\n",
        "* Actual = original or observed y-value,\n",
        "* Forecast = y-value from regression.\n",
        "* Root Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0XXjb_phHlr"
      },
      "source": [
        "# **LINEAR REGRESSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jreWwpjFhHlr"
      },
      "source": [
        "* Regression models describe the relationship between variables by fitting a best fit line to the observed data. Linear regression models use a straight line  using a Fromula the formula is same as straight line equation having an intercept and slope.\n",
        "Y = a + bX, where X is the independent variable and Y is the dependent variable,The slope of the line is b, and a is the intercept "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XHfG4TOhHlr"
      },
      "source": [
        "* Some parameter in  which the algorithm tries to learn using Gradient descent.\n",
        "\n",
        "Gradient descent is the process by which the algorithm tries to update the parameters using  a loss function . Loss function is nothing but the diffence between the actual values and predicted values(residuals error). There are different types of loss function but this is the simplest one. Loss function summed over all observation gives the cost functions. The role of gradient descent is to update the parameters till the cost function is minimized i.e., a global minima is reached. It uses a hyperparameter 'alpha' that gives a weightage to the cost function and decides on how big the steps to take. Alpha is called as the learning rate. It is always necesarry to keep an optimal value of alpha as high and low values of alpha might make the gradient descent overshoot or get stuck at a local minima. There are also some basic assumptions that must be fulfilled before implementing this algorithm. They are:\n",
        "\n",
        "1. No multicollinearity in the dataset.\n",
        "\n",
        "2. Independent variables should show linear relationship with dv.\n",
        "\n",
        "3. Residual mean should be 0 or close to 0.\n",
        "\n",
        "4. There should be no heteroscedasticity i.e., variance should be constant along the line of best fit.\n",
        "\n",
        "\n",
        "\n",
        "Let us now implement our first model.\n",
        "We will be using LinearRegression from scikit library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUv7CaWXhHls"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model= LinearRegression().fit(X_train, y_train)  # here we do both work call model and fit the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af7GUMGfhHls"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "model.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxG8sISYhHls"
      },
      "outputs": [],
      "source": [
        "#check the coefficeint\n",
        "model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osiP_HBkhHls"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train=model.predict(X_train)\n",
        "y_pred_test=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfgIDs6thHlt"
      },
      "source": [
        "## **Check error for train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZs0p6nXhHlt"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE ( mesn square error)\n",
        "MSE_lr= mean_squared_error((y_train), (y_pred_train))\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE ( root mean square error)\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE  (mean aboslute error)\n",
        "MAE_lr= mean_absolute_error(y_train, y_pred_train)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train, y_pred_train)\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZiz-2XhHlt"
      },
      "source": [
        "## **Check error for Test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9YvG-uMhHlu"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error(y_test, y_pred_test)\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_test, y_pred_test)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score((y_test), (y_pred_test))\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score((y_test), (y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print(\"Adjusted R2 :\",Adjusted_R2_lr )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNC08QRwhHlu"
      },
      "outputs": [],
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test),(y_test)-(y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz44LaxlhHlu"
      },
      "source": [
        "# **Lasso Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sb0aS47hHlu"
      },
      "outputs": [],
      "source": [
        "# Create an instance of Lasso Regression implementation\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha=1.0, max_iter=3000)\n",
        "# Fit the Lasso model\n",
        "lasso.fit(X_train, y_train)\n",
        "# Create the model score\n",
        "print(lasso.score(X_test, y_test), lasso.score(X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sqiTzr_hHlv"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_lasso=lasso.predict(X_train)\n",
        "y_pred_test_lasso=lasso.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fSPJfKvhHlv"
      },
      "source": [
        "## **Check eror for train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdLKY_gVhHlv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l= mean_squared_error((y_train), (y_pred_train_lasso))\n",
        "print(\"MSE :\",MSE_l)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l=np.sqrt(MSE_l)\n",
        "print(\"RMSE :\",RMSE_l)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l= mean_absolute_error(y_train, y_pred_train_lasso)\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l= r2_score(y_train, y_pred_train_lasso)\n",
        "print(\"R2 :\",r2_l)\n",
        "Adjusted_R2_l = (1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozzll0UXhHlw"
      },
      "source": [
        "## **Check error for test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNb_oVKYhHlw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l= mean_squared_error(y_test, y_pred_test_lasso)\n",
        "print(\"MSE :\",MSE_l)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l=np.sqrt(MSE_l)\n",
        "print(\"RMSE :\",RMSE_l)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l= mean_absolute_error(y_test, y_pred_test_lasso)\n",
        "print(\"MAE :\",MAE_l)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l= r2_score((y_test), (y_pred_test_lasso))\n",
        "print(\"R2 :\",r2_l)\n",
        "Adjusted_R2_l=(1-(1-r2_score((y_test), (y_pred_test_lasso)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_lasso)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_s9BJ3PhHlz"
      },
      "source": [
        "# **Ridge regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6na-O1ghHl0"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoufB-zwhHl0"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "ridge.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21A1gM2RhHl0"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "ridge.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsDm9T3ehHl1"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuN6ao7ChHl1"
      },
      "source": [
        "### Check error for train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBAVzc2AhHl1"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error((y_train), (y_pred_train_ridge))\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_train, y_pred_train_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score(y_train, y_pred_train_ridge)\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7skECPP8hHl1"
      },
      "source": [
        "### Check error for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCstiaoWhHl2"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error(y_test, y_pred_test_ridge)\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_test, y_pred_test_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score((y_test), (y_pred_test_ridge))\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OnvO4iyhHl2"
      },
      "source": [
        "# **Elastic Net regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STGaqRWIhHl2"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIWvo54ThHl2"
      },
      "outputs": [],
      "source": [
        "#FIT THE MODEL\n",
        "elasticnet.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VXzKUCahHl3"
      },
      "outputs": [],
      "source": [
        "#check the score\n",
        "elasticnet.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ0mKKswhHl3"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(X_train)\n",
        "y_pred_test_en=elasticnet.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkP_MUIIhHl3"
      },
      "source": [
        "## Check error for train test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzKdpz26hHl3"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error((y_train), (y_pred_train_en))\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score(y_train, y_pred_train_en)\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNo8KixzhHl5"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "decision_regressor = DecisionTreeRegressor(criterion='poisson', max_depth=8,\n",
        "                      max_features=9, max_leaf_nodes=100,)\n",
        "decision_regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGftODFEhHl4"
      },
      "source": [
        "## Check error for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cm9wSnLhHl4"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error(y_test, y_pred_test_en)\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_test, y_pred_test_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score((y_test), (y_pred_test_en))\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l37toMAEhHl4"
      },
      "source": [
        "# **Decison Tree**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "decision_regressor = DecisionTreeRegressor(criterion='poisson', max_depth=8,\n",
        "                      max_features=9, max_leaf_nodes=100,)\n",
        "decision_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "SxpmBBvy-_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NYHS6v1hHl5"
      },
      "outputs": [],
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_d = decision_regressor.predict(X_train)\n",
        "y_pred_test_d = decision_regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",decision_regressor.score(X_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_d= mean_squared_error(y_train, y_pred_train_d)\n",
        "print(\"MSE :\",MSE_d)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_d=np.sqrt(MSE_d)\n",
        "print(\"RMSE :\",RMSE_d)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_d= mean_absolute_error(y_train, y_pred_train_d)\n",
        "print(\"MAE :\",MAE_d)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_d= r2_score(y_train, y_pred_train_d)\n",
        "print(\"R2 :\",r2_d)\n",
        "Adjusted_R2_d=(1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "KklXP5DFOX7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_d= mean_squared_error(y_test, y_pred_test_d)\n",
        "print(\"MSE :\",MSE_d)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_d=np.sqrt(MSE_d)\n",
        "print(\"RMSE :\",RMSE_d)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_d= mean_absolute_error(y_test, y_pred_test_d)\n",
        "print(\"MAE :\",MAE_d)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_d= r2_score((y_test), (y_pred_test_d))\n",
        "print(\"R2 :\",r2_d)\n",
        "Adjusted_R2_d=(1-(1-r2_score((y_test), (y_pred_test_d)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_d)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "olAk_78ROt18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((np.array(y_pred_test_d)))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lhoh1xyKOy12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RANDOM FOREST**"
      ],
      "metadata": {
        "id": "UU-8UUU7PPax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Create an instance of the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor()\n",
        "\n",
        "rf_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "HMiQdIHTPLTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "y_pred_train_r = rf_model.predict(X_train)\n",
        "y_pred_test_r = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "8-MMkUJpPn_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",rf_model.score(X_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_train, y_pred_train_r)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_train, y_pred_train_r)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score(y_train, y_pred_train_r)\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score(y_train, y_pred_train_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "yCr9G--pPcad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_test, y_pred_test_r)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_test, y_pred_test_r)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score((y_test), (y_pred_test_r))\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score((y_test), (y_pred_test_r)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_r)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "sNQg_WTzPx21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test_r),(y_test)-(y_pred_test_r))"
      ],
      "metadata": {
        "id": "W4TwfY7XP1VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcMwzZxoAimU"
      },
      "source": [
        "## **5. Solution to Business Objective**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G2x9gOozGDZ"
      },
      "source": [
        "#### What do you suggest the client to achieve Business Objective ? \n",
        "Explain Briefly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pASKb0qOza21"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "Write the conclusion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "NC_X3p0fY2L0",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ebe6247e7a1f1167b5c64aafd6f99eb52db41c0d4edef59d26ba27c8c23c0d56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}